#in "pytorch" Conda Env, as ipython terminal

import pycuda 
import pycuda.driver as drv  
drv.init() 
print('CUDA device query (PyCUDA version) \n') 
print('Detected {} CUDA Capable device(s) \n'.format(drv.Device.count())) 
for i in range(drv.Device.count()): 
     gpu_device = drv.Device(i) 
     print('Device {}: {}'.format( i, gpu_device.name() ) ) 
     compute_capability = float( '%d.%d' % gpu_device.compute_capability() )  
     print('\t Compute Capability:{}'.format(compute_capability))  
     print('\t Total Memory: {}megabytes'.format(gpu_device.total_memory()//(1024**2 )))
     
###########  ###########  ###########  ###########  ###########  ###########  ###########  ###########  ###########  ###########  ###########     
# Expected Output
/**
CUDA device query (PyCUDA version) 

Detected 1 CUDA Capable device(s) 

Device 0: Tesla T4
	 Compute Capability:7.5
	 Total Memory: 15109megabytes
*/
